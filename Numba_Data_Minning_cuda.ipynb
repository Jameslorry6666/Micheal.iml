{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM9aaaNDkft6GIQfccZKAEx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jameslorry6666/Micheal.iml/blob/master/Numba_Data_Minning_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zt9b13V7W74w"
      },
      "outputs": [],
      "source": [
        "#High-performance data processing using the Namba library"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Installing the library\n",
        "!pip install numba"
      ],
      "metadata": {
        "id": "YyfljJ2HXNia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM9QBHrHoqbg",
        "outputId": "d9383eb1-b5b8-4718-f7e9-33c767a94269"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.39.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.18 in /usr/local/lib/python3.10/dist-packages (from numba) (1.22.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba) (67.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "from timeit import default_timer as timer\n",
        "print(cuda.gpus)\n",
        "\n"
      ],
      "metadata": {
        "id": "traJPwHQqh5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a12da86-24fb-425b-fec3-0e5a5eabee32"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Managed Device 0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from numba import cuda\n",
        "gpu = cuda.get_current_device()\n",
        "print(\"name = %s\" % gpu.name)\n",
        "print(\"maxThreadsPerBlock = %s\" % str(gpu.MAX_THREADS_PER_BLOCK))\n",
        "print(\"maxBlockDimX = %s\" % str(gpu.MAX_BLOCK_DIM_X))\n",
        "print(\"maxBlockDimY = %s\" % str(gpu.MAX_BLOCK_DIM_Y))\n",
        "print(\"maxBlockDimZ = %s\" % str(gpu.MAX_BLOCK_DIM_Z))\n",
        "print(\"maxGridDimX = %s\" % str(gpu.MAX_GRID_DIM_X))\n",
        "print(\"maxGridDimY = %s\" % str(gpu.MAX_GRID_DIM_Y))\n",
        "print(\"maxGridDimZ = %s\" % str(gpu.MAX_GRID_DIM_Z))\n",
        "print(\"maxSharedMemoryPerBlock = %s\" % str(gpu.MAX_SHARED_MEMORY_PER_BLOCK))\n",
        "print(\"asyncEngineCount = %s\" % str(gpu.ASYNC_ENGINE_COUNT))\n",
        "print(\"canMapHostMemory = %s\" % str(gpu.CAN_MAP_HOST_MEMORY))\n",
        "print(\"multiProcessorCount = %s\" % str(gpu.MULTIPROCESSOR_COUNT))\n",
        "print(\"warpSize = %s\" % str(gpu.WARP_SIZE))\n",
        "print(\"unifiedAddressing = %s\" % str(gpu.UNIFIED_ADDRESSING))\n",
        "print(\"pciBusID = %s\" % str(gpu.PCI_BUS_ID))\n",
        "print(\"pciDeviceID = %s\" % str(gpu.PCI_DEVICE_ID))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u-AItsf200f",
        "outputId": "1565d8dc-d8f4-4151-c18c-bc91530b55b7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name = b'Tesla T4'\n",
            "maxThreadsPerBlock = 1024\n",
            "maxBlockDimX = 1024\n",
            "maxBlockDimY = 1024\n",
            "maxBlockDimZ = 64\n",
            "maxGridDimX = 2147483647\n",
            "maxGridDimY = 65535\n",
            "maxGridDimZ = 65535\n",
            "maxSharedMemoryPerBlock = 49152\n",
            "asyncEngineCount = 3\n",
            "canMapHostMemory = 1\n",
            "multiProcessorCount = 40\n",
            "warpSize = 32\n",
            "unifiedAddressing = 1\n",
            "pciBusID = 0\n",
            "pciDeviceID = 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "@cuda.jit\n",
        "def dec_kernel(x, y, out):\n",
        "    \n",
        "    idx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x \n",
        "    out[idx] = x[idx] - y[idx]\n",
        "\n"
      ],
      "metadata": {
        "id": "dH0Uu-iW3D29"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "n = 1000000 \n",
        "x = np.arange(n).astype(np.int32) # vectort Ñ… [0...1000000] \n",
        "y = np.ones_like(x)               # [1...1]\n",
        "\n",
        "d_x = cuda.to_device(x) # copy to data of the video card\n",
        "d_y = cuda.to_device(y) # copy to data of the video card\n",
        "d_out = cuda.device_array_like(d_x) # the resulting vector\n",
        "\n",
        " # setting the dimension of the grid\n",
        "threads_per_block = 256\n",
        "blocks_per_grid = math.ceil(n / threads_per_block)"
      ],
      "metadata": {
        "id": "tsyDYya73RcJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = timer()\n",
        "dec_kernel[blocks_per_grid, threads_per_block](d_x, d_y, d_out) # starting the kernel\n",
        "print(\"GPU:\", timer()-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCtXKs4S37oS",
        "outputId": "58e17931-ddc9-4ee5-8fb6-34598e9d9a5d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: 0.00040332300000045507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(d_out.copy_to_host())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbklrhyP4NGb",
        "outputId": "431ff2a7-fc3e-4fc4-9e8f-f1b509738fd8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    -1      0      1 ... 999996 999997 999998]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out  = np.ones(n, dtype = np.int32)\n",
        "\n",
        "def dec_cpu(x, y, out):\n",
        "    for i in range(n):\n",
        "        out[i] = x[i]-y[i]"
      ],
      "metadata": {
        "id": "wFTJ5d0f4ay4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = timer()\n",
        "dec_cpu(x, y, out)\n",
        "print(\"CPU:\", timer()-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzU6A6wN4kC5",
        "outputId": "4c15b73b-535f-421b-8cce-5812a5be1ca3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU: 0.2778614159999506\n"
          ]
        }
      ]
    }
  ]
}